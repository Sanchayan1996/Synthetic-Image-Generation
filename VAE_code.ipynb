# -*- coding: utf-8 -*-
"""
Spyder Editor

This is a temporary script file.
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
from torchvision.utils import save_image, make_grid
from PIL import Image
import matplotlib.pyplot as plt

# Define the VAE architecture
class VAE(nn.Module):
    def __init__(self, latent_dim):
        super(VAE, self).__init__()
        self.latent_dim = latent_dim

        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 32, 4, 2, 1),
            nn.ReLU(),
            nn.Conv2d(32, 64, 4, 2, 1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.ReLU(),
            nn.Flatten()
        )
        self.fc_mu = nn.Linear(128*8*8, latent_dim)
        self.fc_logvar = nn.Linear(128*8*8, latent_dim)

        # Decoder
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 128*8*8),
            nn.ReLU(),
            nn.Unflatten(1, (128, 8, 8)),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 3, 4, 2, 1),
            nn.Sigmoid()
        )

    def encode(self, x):
        h = self.encoder(x)
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def decode(self, z):
        return self.decoder(z)

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar

# Loss function
def loss_function(recon_x, x, mu, logvar):
    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return BCE + KLD

# Hyperparameters
latent_dim = 20
learning_rate = 0.001
batch_size = 64
n_epochs = 150

# Define image transformations
transform = transforms.Compose([
    transforms.Resize((64, 64)),  # Resize images to 64x64 for training
    transforms.ToTensor()
])

# Create a custom dataset class to load images
class CustomDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.image_files = [os.path.join(root_dir, file) for file in os.listdir(root_dir) if file.endswith(('jpg', 'png'))]

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        image = Image.open(img_path)
        if self.transform:
            image = self.transform(image)
        return image

def main():
    # Load your dataset
    data_directory = r'C:\PROJECT\Emotion_dataset\New Augmented dataset_Happy'
    dataset = CustomDataset(root_dir=data_directory, transform=transform)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Initialize model and optimizer
    vae = VAE(latent_dim)
    optimizer = optim.Adam(vae.parameters(), lr=learning_rate)

    # Training loop
    for epoch in range(n_epochs):
        vae.train()
        train_loss = 0
        for i, imgs in enumerate(dataloader):
            optimizer.zero_grad()
            recon_imgs, mu, logvar = vae(imgs)
            loss = loss_function(recon_imgs, imgs, mu, logvar)
            loss.backward()
            train_loss += loss.item()
            optimizer.step()

            if i % 100 == 0:
                print(f'Epoch [{epoch}/{n_epochs}] Batch {i}/{len(dataloader)} Loss: {loss.item() / len(imgs)}')

        print(f'====> Epoch: {epoch} Average loss: {train_loss / len(dataloader.dataset)}')

        # Save generated images
        generated_images_dir = r'C:\PROJECT\Emotion_dataset\Generated images\150 epochs'
        os.makedirs(generated_images_dir, exist_ok=True)
        with torch.no_grad():
            sample = torch.randn(64, latent_dim)
            generated_images = vae.decode(sample).cpu()
            generated_images = nn.functional.interpolate(generated_images, size=128, mode='bilinear')
            save_image(generated_images, os.path.join(generated_images_dir, f'VAE_sample_{epoch}.png'), nrow=8, normalize=True)
            print(f'Generated images saved to {generated_images_dir}')

    # Generate and save 10 images after training
    vae_images_dir = r'C:\PROJECT\Emotion_dataset\VAE\150 epochs'
    os.makedirs(vae_images_dir, exist_ok=True)
    vae.eval()
    with torch.no_grad():
        for i in range(10):
            sample = torch.randn(1, latent_dim)
            generated_image = vae.decode(sample).cpu()
            generated_image = nn.functional.interpolate(generated_image, size=128, mode='bilinear')
            save_image(generated_image, os.path.join(vae_images_dir, f'VAE_image_{i}.png'), normalize=True)
            print(f'Generated image {i} saved to {vae_images_dir}')

    # Visualize some generated images
    vae.eval()
    with torch.no_grad():
        sample = torch.randn(64, latent_dim)
        generated_images = vae.decode(sample).cpu()
        generated_images = nn.functional.interpolate(generated_images, size=128, mode='bilinear')
        grid_img = make_grid(generated_images, nrow=8, normalize=True)
        plt.imshow(grid_img.permute(1, 2, 0))
        plt.show()

if __name__ == "__main__":
    main()
